{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfacd12b-cba9-4265-a94f-336c6d570746",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opencv-python mediapipe numpy pillow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ce2d69-5b3e-45bc-8a69-67fed5969367",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "from PIL import Image\n",
    "import io\n",
    "import tempfile\n",
    "import matplotlib.pyplot as plt\n",
    "import gradio as gr\n",
    "from openai import OpenAI\n",
    "\n",
    "# ðŸ”¹ Initialize OpenAI client\n",
    "client = OpenAI(api_key=\"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\")\n",
    "\n",
    "# ---------------- Species Classification ---------------- #\n",
    "def classify_species(image_bytes: bytes) -> dict:\n",
    "    try:\n",
    "        image = Image.open(io.BytesIO(image_bytes))\n",
    "        width, height = image.size\n",
    "        if width < height:\n",
    "            species = \"Gir Cow\"\n",
    "            confidence = np.random.uniform(0.90, 0.99)\n",
    "        else:\n",
    "            species = \"Murrah Buffalo\"\n",
    "            confidence = np.random.uniform(0.88, 0.98)\n",
    "        return {\"species\": species, \"confidence\": float(confidence)}\n",
    "    except Exception as e:\n",
    "        return {\"species\": \"Error\", \"confidence\": 0.0}\n",
    "\n",
    "# ---------------- Pose Estimation ---------------- #\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose(static_image_mode=False, model_complexity=1, min_detection_confidence=0.5)\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "def extract_keypoints_from_video(video_path: str) -> list:\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    keypoints_data = []\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "        results = pose.process(image)\n",
    "        if results.pose_landmarks:\n",
    "            frame_keypoints = {}\n",
    "            for i, landmark in enumerate(results.pose_landmarks.landmark):\n",
    "                if i in [23, 24, 25, 26, 27, 28]:  # hips, knees, ankles\n",
    "                    landmark_name = mp_pose.PoseLandmark(i).name\n",
    "                    frame_keypoints[landmark_name] = {\n",
    "                        \"x\": landmark.x,\n",
    "                        \"y\": landmark.y,\n",
    "                        \"z\": landmark.z,\n",
    "                        \"visibility\": landmark.visibility\n",
    "                    }\n",
    "            if frame_keypoints:\n",
    "                keypoints_data.append(frame_keypoints)\n",
    "    cap.release()\n",
    "    return keypoints_data\n",
    "\n",
    "# ---------------- Gait Analysis ---------------- #\n",
    "def calculate_mobility_score(keypoints_data: list) -> dict:\n",
    "    if len(keypoints_data) < 15:\n",
    "        return {\"mobility_score\": -1, \"score_type\": \"Insufficient Video Length\"}\n",
    "\n",
    "    left_hip_y = [frame.get('LEFT_HIP', {}).get('y') for frame in keypoints_data]\n",
    "    right_hip_y = [frame.get('RIGHT_HIP', {}).get('y') for frame in keypoints_data]\n",
    "    left_hip_y = [y for y in left_hip_y if y is not None]\n",
    "    right_hip_y = [y for y in right_hip_y if y is not None]\n",
    "\n",
    "    if len(left_hip_y) < 10 or len(right_hip_y) < 10:\n",
    "        return {\"mobility_score\": -1, \"score_type\": \"Could Not Track Hips\"}\n",
    "\n",
    "    std_dev_left = np.std(left_hip_y)\n",
    "    std_dev_right = np.std(right_hip_y)\n",
    "    avg_bobbing_motion = (std_dev_left + std_dev_right) / 2\n",
    "\n",
    "    if avg_bobbing_motion < 0.01:\n",
    "        score = 0\n",
    "        score_type = \"Prime Mobility\"\n",
    "    elif avg_bobbing_motion < 0.025:\n",
    "        score = 1\n",
    "        score_type = \"At-Risk\"\n",
    "    else:\n",
    "        score = 2\n",
    "        score_type = \"Lame Mobility Detected\"\n",
    "\n",
    "    return {\"mobility_score\": score, \"score_type\": score_type}\n",
    "\n",
    "# ---------------- Pose Visualization ---------------- #\n",
    "def visualize_pose(video_path: str, num_frames: int = 5):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    shown = 0\n",
    "    frames = []\n",
    "    while cap.isOpened() and shown < num_frames:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = pose.process(image_rgb)\n",
    "        if results.pose_landmarks:\n",
    "            mp_drawing.draw_landmarks(image_rgb, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "            img_pil = Image.fromarray(image_rgb)\n",
    "            frames.append(img_pil)\n",
    "            shown += 1\n",
    "    cap.release()\n",
    "    return frames\n",
    "\n",
    "# ---------------- Health Inspector (ChatGPT) ---------------- #\n",
    "def health_inspector(gait_data, species_data):\n",
    "    prompt = f\"\"\"\n",
    "    You are a veterinary health inspector.\n",
    "    Here is the gait analysis result of a {species_data['species']}:\n",
    "    - Mobility Score: {gait_data['mobility_score']}\n",
    "    - Score Type: {gait_data['score_type']}\n",
    "    Confidence in classification: {species_data['confidence']:.2f}\n",
    "\n",
    "    Give a detailed health assessment.\n",
    "    Mention possible conditions, risks, and recommended actions.\n",
    "    Keep it clear and practical.\n",
    "    \"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",  # You can use gpt-4o or gpt-4.1 for more detail\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a veterinary health inspector.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# ---------------- Gradio Pipeline ---------------- #\n",
    "def pipeline(video_file):\n",
    "    # Save uploaded video temporarily\n",
    "    with tempfile.NamedTemporaryFile(delete=False, suffix=\".mp4\") as temp_file:\n",
    "        temp_file.write(video_file)\n",
    "        temp_path = temp_file.name\n",
    "\n",
    "    # Step 1: Classification\n",
    "    cap = cv2.VideoCapture(temp_path)\n",
    "    ret, frame = cap.read()\n",
    "    cap.release()\n",
    "    if ret:\n",
    "        _, buffer = cv2.imencode('.jpg', frame)\n",
    "        classification_result = classify_species(buffer.tobytes())\n",
    "    else:\n",
    "        classification_result = {\"species\": \"Error\", \"confidence\": 0.0}\n",
    "\n",
    "    # Step 2: Pose Estimation\n",
    "    keypoints_data = extract_keypoints_from_video(temp_path)\n",
    "\n",
    "    # Step 3: Gait Analysis\n",
    "    gait_result = calculate_mobility_score(keypoints_data)\n",
    "\n",
    "    # Step 4: Visualization\n",
    "    vis_frames = visualize_pose(temp_path, num_frames=5)\n",
    "\n",
    "    # Step 5: Health Inspector Report\n",
    "    health_report = health_inspector(gait_result, classification_result)\n",
    "\n",
    "    return classification_result, gait_result, vis_frames, health_report\n",
    "\n",
    "# ---------------- Gradio UI ---------------- #\n",
    "with gr.Blocks() as app:\n",
    "    gr.Markdown(\"## ðŸ„ Cattle Gait Analysis & Health Inspector\")\n",
    "\n",
    "    video_input = gr.File(label=\"Upload Cattle Walking Video\", type=\"binary\")\n",
    "\n",
    "    with gr.Row():\n",
    "        species_output = gr.JSON(label=\"Species Classification\")\n",
    "        gait_output = gr.JSON(label=\"Gait Analysis\")\n",
    "\n",
    "    vis_output = gr.Gallery(label=\"Pose Visualization\", columns=2, height=\"auto\")\n",
    "    report_output = gr.Textbox(label=\"Health Inspector Report\", lines=12)\n",
    "\n",
    "    analyze_btn = gr.Button(\"Run Analysis\")\n",
    "\n",
    "    analyze_btn.click(\n",
    "        fn=pipeline,\n",
    "        inputs=video_input,\n",
    "        outputs=[species_output, gait_output, vis_output, report_output]\n",
    "    )\n",
    "\n",
    "app.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e75900c-3acf-4dc6-8aeb-e73d821676bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "from PIL import Image\n",
    "import io\n",
    "import tempfile\n",
    "import matplotlib.pyplot as plt\n",
    "import gradio as gr\n",
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "\n",
    "# ðŸ”¹ OpenAI Client\n",
    "client = OpenAI(api_key=\"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\")\n",
    "\n",
    "# ðŸ”¹ Storage for cow health records\n",
    "cow_records = {}\n",
    "\n",
    "# ---------------- Species Classification ---------------- #\n",
    "def classify_species(image_bytes: bytes) -> dict:\n",
    "    try:\n",
    "        image = Image.open(io.BytesIO(image_bytes))\n",
    "        width, height = image.size\n",
    "        if width < height:\n",
    "            species = \"Gir Cow\"\n",
    "            confidence = np.random.uniform(0.90, 0.99)\n",
    "        else:\n",
    "            species = \"Murrah Buffalo\"\n",
    "            confidence = np.random.uniform(0.88, 0.98)\n",
    "        return {\"species\": species, \"confidence\": float(confidence)}\n",
    "    except:\n",
    "        return {\"species\": \"Error\", \"confidence\": 0.0}\n",
    "\n",
    "# ---------------- Pose Estimation ---------------- #\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose(static_image_mode=False, model_complexity=1, min_detection_confidence=0.5)\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "def extract_keypoints_from_video(video_path: str) -> list:\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    keypoints_data = []\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = pose.process(image)\n",
    "        if results.pose_landmarks:\n",
    "            frame_keypoints = {}\n",
    "            for i, landmark in enumerate(results.pose_landmarks.landmark):\n",
    "                if i in [23, 24, 25, 26, 27, 28]:  # hips, knees, ankles\n",
    "                    landmark_name = mp_pose.PoseLandmark(i).name\n",
    "                    frame_keypoints[landmark_name] = {\n",
    "                        \"x\": landmark.x,\n",
    "                        \"y\": landmark.y,\n",
    "                        \"z\": landmark.z,\n",
    "                        \"visibility\": landmark.visibility\n",
    "                    }\n",
    "            if frame_keypoints:\n",
    "                keypoints_data.append(frame_keypoints)\n",
    "    cap.release()\n",
    "    return keypoints_data\n",
    "\n",
    "# ---------------- Gait Analysis ---------------- #\n",
    "def calculate_mobility_score(keypoints_data: list) -> dict:\n",
    "    if len(keypoints_data) < 15:\n",
    "        return {\"mobility_score\": -1, \"score_type\": \"Insufficient Video Length\"}\n",
    "    left_hip_y = [frame.get('LEFT_HIP', {}).get('y') for frame in keypoints_data]\n",
    "    right_hip_y = [frame.get('RIGHT_HIP', {}).get('y') for frame in keypoints_data]\n",
    "    left_hip_y = [y for y in left_hip_y if y is not None]\n",
    "    right_hip_y = [y for y in right_hip_y if y is not None]\n",
    "    if len(left_hip_y) < 10 or len(right_hip_y) < 10:\n",
    "        return {\"mobility_score\": -1, \"score_type\": \"Could Not Track Hips\"}\n",
    "    std_dev_left = np.std(left_hip_y)\n",
    "    std_dev_right = np.std(right_hip_y)\n",
    "    avg_bobbing_motion = (std_dev_left + std_dev_right) / 2\n",
    "    if avg_bobbing_motion < 0.01:\n",
    "        score, score_type = 0, \"Prime Mobility\"\n",
    "    elif avg_bobbing_motion < 0.025:\n",
    "        score, score_type = 1, \"At-Risk\"\n",
    "    else:\n",
    "        score, score_type = 2, \"Lame Mobility Detected\"\n",
    "    return {\"mobility_score\": score, \"score_type\": score_type}\n",
    "\n",
    "# ---------------- Pose Visualization ---------------- #\n",
    "def visualize_pose(video_path: str, num_frames: int = 5):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    shown, frames = 0, []\n",
    "    while cap.isOpened() and shown < num_frames:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = pose.process(image_rgb)\n",
    "        if results.pose_landmarks:\n",
    "            mp_drawing.draw_landmarks(image_rgb, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "            frames.append(Image.fromarray(image_rgb))\n",
    "            shown += 1\n",
    "    cap.release()\n",
    "    return frames\n",
    "\n",
    "# ---------------- Health Inspector ---------------- #\n",
    "def health_inspector(gait_data, species_data):\n",
    "    prompt = f\"\"\"\n",
    "    You are a veterinary health inspector.\n",
    "    Here is the gait analysis result of a {species_data['species']}:\n",
    "    - Mobility Score: {gait_data['mobility_score']}\n",
    "    - Score Type: {gait_data['score_type']}\n",
    "    Confidence in classification: {species_data['confidence']:.2f}\n",
    "\n",
    "    Provide a health assessment with possible conditions, risks, and actions.\n",
    "    \"\"\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a veterinary health inspector.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# ---------------- Pipeline with Cow Number ---------------- #\n",
    "def pipeline(cow_id, video_file):\n",
    "    with tempfile.NamedTemporaryFile(delete=False, suffix=\".mp4\") as temp_file:\n",
    "        temp_file.write(video_file)\n",
    "        temp_path = temp_file.name\n",
    "\n",
    "    # Classification\n",
    "    cap = cv2.VideoCapture(temp_path)\n",
    "    ret, frame = cap.read()\n",
    "    cap.release()\n",
    "    if ret:\n",
    "        _, buffer = cv2.imencode('.jpg', frame)\n",
    "        classification_result = classify_species(buffer.tobytes())\n",
    "    else:\n",
    "        classification_result = {\"species\": \"Error\", \"confidence\": 0.0}\n",
    "\n",
    "    # Pose Estimation & Gait\n",
    "    keypoints_data = extract_keypoints_from_video(temp_path)\n",
    "    gait_result = calculate_mobility_score(keypoints_data)\n",
    "    vis_frames = visualize_pose(temp_path, num_frames=5)\n",
    "    health_report = health_inspector(gait_result, classification_result)\n",
    "\n",
    "    # Save record\n",
    "    cow_records[cow_id] = {\n",
    "        \"species\": classification_result,\n",
    "        \"gait\": gait_result,\n",
    "        \"report\": health_report\n",
    "    }\n",
    "\n",
    "    return classification_result, gait_result, vis_frames, health_report\n",
    "\n",
    "# ---------------- View All Records ---------------- #\n",
    "def view_records():\n",
    "    if not cow_records:\n",
    "        return \"No records yet.\"\n",
    "    df = []\n",
    "    for cow, data in cow_records.items():\n",
    "        df.append({\n",
    "            \"Cow ID\": cow,\n",
    "            \"Species\": data[\"species\"][\"species\"],\n",
    "            \"Mobility\": data[\"gait\"][\"score_type\"],\n",
    "            \"Report (summary)\": data[\"report\"][:80] + \"...\"\n",
    "        })\n",
    "    return pd.DataFrame(df)\n",
    "\n",
    "# ---------------- Gradio UI ---------------- #\n",
    "with gr.Blocks() as app:\n",
    "    gr.Markdown(\"## ðŸ„ Multi-Cow Gait Health Inspector\")\n",
    "\n",
    "    with gr.Row():\n",
    "        cow_id = gr.Textbox(label=\"Enter Cow ID / Number\", placeholder=\"e.g. Cow-1\")\n",
    "        video_input = gr.File(label=\"Upload Cattle Walking Video\", type=\"binary\")\n",
    "\n",
    "    with gr.Row():\n",
    "        species_output = gr.JSON(label=\"Species Classification\")\n",
    "        gait_output = gr.JSON(label=\"Gait Analysis\")\n",
    "\n",
    "    vis_output = gr.Gallery(label=\"Pose Visualization\", columns=2, height=\"auto\")\n",
    "    report_output = gr.Textbox(label=\"Health Inspector Report\", lines=12)\n",
    "\n",
    "    analyze_btn = gr.Button(\"Run Analysis\")\n",
    "    analyze_btn.click(\n",
    "        fn=pipeline,\n",
    "        inputs=[cow_id, video_input],\n",
    "        outputs=[species_output, gait_output, vis_output, report_output]\n",
    "    )\n",
    "\n",
    "    gr.Markdown(\"### ðŸ“’ Farmer's Health Record\")\n",
    "    record_btn = gr.Button(\"View All Cow Records\")\n",
    "    record_output = gr.Dataframe(label=\"Cow Records\")\n",
    "    record_btn.click(view_records, inputs=None, outputs=record_output)\n",
    "\n",
    "app.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e87ca54-735c-464f-a174-318c8be9da5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
